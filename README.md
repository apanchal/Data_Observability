# ğŸ“Š Data Observability & Source ROI SDK

A modular, cloud-agnostic Python SDK designed to monitor, validate, and evaluate the health and ROI of data sources across any data pipeline â€” batch or streaming, pandas or Spark, on-prem or cloud.

---

## ğŸš€ Features

### ğŸ” Data Observability
Implements the five pillars of observability:
- **Freshness** â€“ Is the data arriving on time?
- **Volume** â€“ Are we receiving the expected amount?
- **Schema** â€“ Has the structure changed?
- **Distribution** â€“ Are values within expected ranges?
- **Lineage** â€“ Where does the data come from?

### ğŸ“ˆ Source ROI Framework
Quantifies vendor/source performance using:
- Freshness, Completeness, Usability
- Cost-efficiency, Error Rate, Rework Time
- Product Impact
- **ROI Score** = `wâ‚*(Usable%) + wâ‚‚*(Coverage%) - wâ‚ƒ*(Error%) - wâ‚„*(Cost/GB)`

### ğŸ§© Plug-and-Play SDK
- Works with **pandas** and **Spark DataFrames**
- Supports **YAML-based rule configs**
- Emits metrics to any collector endpoint
- Easily integrates with **Airflow DAGs**

---

## ğŸ—‚ï¸ Project Structure
data_observability_sdk/ 
â”œâ”€â”€ config.py # Environment config 
â”œâ”€â”€ emitter.py # Metric emission logic 
â”œâ”€â”€ metrics.py # Observability metric computation 
â”œâ”€â”€ roi.py # ROI score calculation 
â”œâ”€â”€ rule_engine.py # YAML-based rule evaluation 
â”œâ”€â”€ utils.py # Schema extraction, helpers 
â”œâ”€â”€ sample_usage.py # Example with pandas 
â”œâ”€â”€ spark_support.py # Spark DataFrame support 
â”œâ”€â”€ airflow_dag.py # Airflow DAG integration 
â””â”€â”€ rules.yaml # Sample rule definitions


